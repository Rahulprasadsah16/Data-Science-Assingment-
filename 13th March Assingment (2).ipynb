{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974d4ce1",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96060b6",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical method used for comparing means of three or more groups. Like any statistical technique, ANOVA has certain assumptions that, if violated, can impact the validity of the results. Here are the key assumptions of ANOVA:\n",
    "\n",
    "Normality: The dependent variable should be normally distributed within each group. While ANOVA is known for being robust to moderate violations of normality, severe departures from normality can affect the results. Violations could include highly skewed or heavy-tailed distributions.\n",
    "\n",
    "Homogeneity of Variances (Homoscedasticity): The variances of the dependent variable should be approximately equal across all groups. This assumption is crucial for the robustness of ANOVA. Violations, known as heteroscedasticity, can lead to inflated Type I error rates and affect the precision of the estimated group means.\n",
    "\n",
    "Independence: Observations within and between groups should be independent. This means that the value of one observation should not be influenced by the value of another observation. Violations of independence could occur in repeated measures or clustered data, where observations within the same group are not independent.\n",
    "\n",
    "Examples of Violations and Their Impact:\n",
    "\n",
    "Non-Normality:\n",
    "\n",
    "Example: Suppose a dataset has a highly skewed distribution within one group.\n",
    "Impact: ANOVA is generally robust to mild deviations from normality. However, severe non-normality may lead to unreliable results. In such cases, transformations or non-parametric alternatives might be considered.\n",
    "Heteroscedasticity:\n",
    "\n",
    "Example: Unequal variances between groups.\n",
    "Impact: Heteroscedasticity can lead to inaccurate assessment of group differences. Performing a Welch's ANOVA, which is less sensitive to unequal variances, or using a transformation may be alternatives.\n",
    "Dependent Observations:\n",
    "\n",
    "Example: Observations within groups are correlated, as in a repeated measures design.\n",
    "Impact: Violating independence can lead to underestimation of standard errors, affecting the precision of the estimated means. Mixed-effects models or repeated measures ANOVA may be more appropriate.\n",
    "Outliers:\n",
    "\n",
    "Example: Extreme values in one or more groups.\n",
    "Impact: Outliers can affect the estimation of group means and inflate Type I error rates. Robust ANOVA methods or data transformation may be considered.\n",
    "Categorical Variables:\n",
    "\n",
    "Example: Including categorical variables as covariates without proper consideration.\n",
    "Impact: Misinterpretation of results and violation of assumptions. ANCOVA (ANOVA with covariates) assumes that covariates have a linear relationship with the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198e66b",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe0008",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) can be categorized into three main types based on the design of the study and the number of independent variables involved:\n",
    "\n",
    "One-Way ANOVA:\n",
    "\n",
    "Situation: Used when there is one categorical independent variable (factor) with two or more levels (groups), and the dependent variable is continuous.\n",
    "Example: Examining if there are differences in test scores among students taught by different teachers (where the teachers represent the levels of the factor).\n",
    "Two-Way ANOVA:\n",
    "\n",
    "Situation: Used when there are two independent variables (factors) simultaneously influencing the dependent variable. It explores the interaction effect between the two factors and their individual effects.\n",
    "Example: Investigating the effects of both treatment (drug dosage) and gender on the response variable (e.g., blood pressure). Here, treatment and gender are the two factors.\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Situation: Used when measurements are taken on the same subjects under different conditions or at different time points. It accounts for the within-subject variability.\n",
    "Example: Assessing the impact of a new teaching method on students' performance by measuring their test scores before, during, and after the intervention. Each student serves as their control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa2d72a",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f06df7",
   "metadata": {},
   "source": [
    "The partitioning of variance in Analysis of Variance (ANOVA) refers to the breakdown of the total variance observed in the data into different components associated with various sources of variation. Understanding this concept is crucial because it allows researchers to assess the relative importance of different factors or sources that may influence the variability in the dependent variable.\n",
    "\n",
    "In ANOVA, the total variance observed in the data is divided into three main components:\n",
    "\n",
    "Between-Group Variance (SSB):\n",
    "\n",
    "Definition: Represents the variability among the group means.\n",
    "Interpretation: Measures how much the group means differ from each other. A larger SSB suggests that there are significant differences between at least some of the group means.\n",
    "\n",
    "    \n",
    "Within-Group Variance (SSW):\n",
    "\n",
    "Definition: Represents the variability within each group.\n",
    "Interpretation: Measures the variability of individual observations around their respective group means. A larger SSW indicates greater variability within groups.\n",
    "\n",
    "Total Variance (SST):\n",
    "\n",
    "Definition: Represents the overall variability in the data.\n",
    "Interpretation: The sum of the squared differences between each observation and the grand mean. SST is the sum of both SSB and SSW. It reflects the total variability in the data.\n",
    "\n",
    "The importance of understanding the partitioning of variance in ANOVA lies in its ability to provide insights into the factors contributing to variability in the dependent variable. Researchers can use this information to:\n",
    "\n",
    "Assess Group Differences: By examining the magnitude of SSB, researchers can determine if there are significant differences between the group means.\n",
    "\n",
    "Evaluate Homogeneity of Groups: Comparing SSW with SSB helps assess whether the variability within groups is similar or if there are groups with significantly different variances.\n",
    "\n",
    "Interpret Overall Variability: SST provides a reference point for understanding the total variability in the data. It serves as a baseline against which the contributions of between-group and within-group variability are evaluated.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc17c949",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0790060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 651.7777777777776\n",
      "Explained Sum of Squares (SSE): 468.7777777777778\n",
      "Residual Sum of Squares (SSR): 183.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_way_anova_sums_of_squares(groups):\n",
    "    # Combine all data into a single array\n",
    "    all_data = np.concatenate(groups)\n",
    "\n",
    "    # Calculate the grand mean\n",
    "    grand_mean = np.mean(all_data)\n",
    "\n",
    "    # Calculate Total Sum of Squares (SST)\n",
    "    sst = np.sum((all_data - grand_mean)**2)\n",
    "\n",
    "    # Calculate Explained Sum of Squares (SSE)\n",
    "    sse = np.sum([len(group) * (np.mean(group) - grand_mean)**2 for group in groups])\n",
    "\n",
    "    # Calculate Residual Sum of Squares (SSR)\n",
    "    ssr = np.sum([(x - np.mean(group))**2 for group in groups for x in group])\n",
    "\n",
    "    return sst, sse, ssr\n",
    "\n",
    "# Example data for three groups\n",
    "group1 = [80, 85, 90, 92, 87, 83]\n",
    "group2 = [75, 78, 82, 79, 81, 84]\n",
    "group3 = [70, 72, 76, 74, 77, 73]\n",
    "\n",
    "# Calculate sums of squares\n",
    "sst, sse, ssr = one_way_anova_sums_of_squares([group1, group2, group3])\n",
    "\n",
    "# Print the results\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60963b6e",
   "metadata": {},
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6de018",
   "metadata": {},
   "source": [
    "In a two-way ANOVA, you can calculate the main effects and interaction effects for each independent variable using :\n",
    "Main Effect of Factor A \n",
    "Main Effect of Factor B \n",
    "Interaction Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c603b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "import numpy as np\n",
    "\n",
    "def two_way_anova_effects(data):\n",
    "    # Get the dimensions of the data\n",
    "    I, J = data.shape\n",
    "\n",
    "    # Calculate the grand mean\n",
    "    grand_mean = np.mean(data)\n",
    "\n",
    "    # Calculate Main Effect of Factor A (Main Effect A)\n",
    "    mea = np.mean(data, axis=1) - grand_mean\n",
    "\n",
    "    # Calculate Main Effect of Factor B (Main Effect B)\n",
    "    meb = np.mean(data, axis=0) - grand_mean\n",
    "\n",
    "    # Calculate Interaction Effect (Interaction AB)\n",
    "    ia = grand_mean - np.mean(data) - mea - meb\n",
    "\n",
    "    return mea, meb, ia\n",
    "\n",
    "# Example data for a 2x3 design (2 levels of Factor A, 3 levels of Factor B)\n",
    "data = np.array([[10, 12, 14],\n",
    "                 [15, 18, 21]])\n",
    "\n",
    "# Calculate main effects and interaction effect\n",
    "mea, meb, ia = two_way_anova_effects(data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Main Effect of Factor A (MEA):\", mea)\n",
    "print(\"Main Effect of Factor B (MEB):\", meb)\n",
    "print(\"Interaction Effect (IA):\", ia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc300fd1",
   "metadata": {},
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d315d",
   "metadata": {},
   "source": [
    "\n",
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences among the means of three or more groups. The associated p-value helps determine the statistical significance of the observed differences. Here's how to interpret the given results:\n",
    "\n",
    "F-Statistic:\n",
    "\n",
    "Value (Given): 5.23\n",
    "Interpretation: The F-statistic represents the ratio of the variability between group means to the variability within groups. A higher F-value indicates a larger between-group variability relative to within-group variability.\n",
    "P-Value:\n",
    "\n",
    "Value (Given): 0.02\n",
    "Interpretation: The p-value is the probability of observing such extreme F-statistic results if the null hypothesis (no group differences) were true. A smaller p-value suggests stronger evidence against the null hypothesis.\n",
    "Conclusion:\n",
    "\n",
    "P-Value < Significance Level (e.g., 0.05): If the p-value is less than the chosen significance level (commonly 0.05), you reject the null hypothesis.\n",
    "Interpretation: In this case (p-value = 0.02 < 0.05), there is enough evidence to reject the null hypothesis. This implies that there are statistically significant differences among at least some of the group means.\n",
    "Post hoc Tests (if applicable):\n",
    "\n",
    "If your one-way ANOVA indicates significant differences, you may perform post hoc tests (e.g., Tukey's HSD, Bonferroni) to identify which specific groups differ from each other.\n",
    "Effect Size:\n",
    "\n",
    "Additionally, it is often useful to consider the effect size, such as eta-squared (η^2), which quantifies the proportion of total variability in the dependent variable explained by group membership."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d633eb6",
   "metadata": {},
   "source": [
    "# 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0f994",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is an important consideration to ensure accurate and unbiased results. There are several methods to handle missing data, each with its own potential consequences. Here are some common approaches:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "Handling: Exclude any participant with missing data from the analysis.\n",
    "Consequences: Reduces the sample size, potentially leading to biased results, loss of statistical power, and decreased generalizability. The assumption is that missing data are missing completely at random (MCAR).\n",
    "Mean Imputation:\n",
    "\n",
    "Handling: Replace missing values with the mean of the observed values for that variable.\n",
    "Consequences: Preserves the sample size but may introduce bias if data are not missing completely at random. It assumes that missing values have the same mean as observed values.\n",
    "Last Observation Carried Forward (LOCF):\n",
    "\n",
    "Handling: Impute missing values with the last observed value for that participant.\n",
    "Consequences: Assumes that the participant's last observed value is a good estimate of the missing value. This method may not be suitable for all types of data and can lead to biased results, especially if there is a trend in the data.\n",
    "Linear Interpolation:\n",
    "\n",
    "Handling: Estimate missing values by linearly interpolating between adjacent observed values.\n",
    "Consequences: Assumes a linear relationship between observed values. This method may be suitable for continuous variables with a clear pattern.\n",
    "Multiple Imputation:\n",
    "\n",
    "Handling: Generate multiple datasets with imputed values, incorporating uncertainty about missing data.\n",
    "Consequences: Provides more accurate estimates and standard errors, accounting for variability in imputations. However, it requires additional assumptions about the missing data mechanism and can be computationally intensive.\n",
    "Model-Based Imputation:\n",
    "\n",
    "Handling: Impute missing values based on a statistical model, such as regression imputation.\n",
    "Consequences: Assumes a specific relationship between variables. Can be more accurate than simple imputation methods but requires careful model specification.\n",
    "Maximum Likelihood Estimation (MLE):\n",
    "\n",
    "Handling: Estimate model parameters using all available data, including incomplete cases.\n",
    "Consequences: Provides unbiased estimates if the missing data mechanism is ignorable and can make efficient use of available data. However, it requires assumptions about the missing data mechanism.\n",
    "\n",
    "Potential Consequences:\n",
    "\n",
    "Bias: The chosen method may introduce bias if the missing data mechanism is not completely random.\n",
    "Loss of Power: Complete case analysis reduces the sample size and statistical power.\n",
    "Invalid Inferences: Choosing an inappropriate imputation method can lead to invalid inferences.\n",
    "Assumption Violations: Imputation methods assume a certain distribution or relationship between variables, which may not hold in the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3e36f",
   "metadata": {},
   "source": [
    "# 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b597d6",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after an Analysis of Variance (ANOVA) to identify specific group differences when the overall ANOVA indicates that there are significant differences among groups. Common post-hoc tests include:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "When to Use: Use Tukey's HSD when you have three or more groups, and you want to test all possible pairwise comparisons.\n",
    "Example: In a study comparing the mean scores of four different teaching methods, an ANOVA indicates significant differences among the groups. Tukey's HSD can be used to identify which pairs of teaching methods differ significantly.\n",
    "Bonferroni Correction:\n",
    "\n",
    "When to Use: Use Bonferroni correction when you have three or more groups, and you want to control the familywise error rate by adjusting the significance level for each pairwise comparison.\n",
    "Example: In a clinical trial comparing the efficacy of four treatments, an ANOVA indicates significant differences. To conduct pairwise comparisons while controlling the overall Type I error rate, Bonferroni correction can be applied.\n",
    "Sidak Correction:\n",
    "\n",
    "When to Use: Similar to Bonferroni, Sidak correction is used to control the familywise error rate but may be less conservative for larger numbers of comparisons.\n",
    "Example: In a marketing study comparing the mean sales across five different promotional strategies, an ANOVA suggests significant differences. Sidak correction can be applied to conduct pairwise comparisons while controlling the overall Type I error rate.\n",
    "Duncan's Multiple Range Test:\n",
    "\n",
    "When to Use: Duncan's test is used when you have three or more groups, and you want to identify specific group differences.\n",
    "Example: In an agricultural experiment comparing the yields of five different fertilizers, an ANOVA reveals significant differences. Duncan's test can help identify which pairs of fertilizers result in significantly different yields.\n",
    "Games-Howell Test:\n",
    "\n",
    "When to Use: Use the Games-Howell test when the assumption of equal variances is violated, and you have three or more groups.\n",
    "Example: In a psychology study comparing the mean scores of three different therapeutic interventions, an ANOVA shows significant differences. As the variances are unequal, the Games-Howell test can be used for pairwise comparisons.\n",
    "Bonferroni-Dunn Test:\n",
    "\n",
    "When to Use: The Bonferroni-Dunn test is used when you have multiple treatments and a control group, and you want to compare each treatment with the control.\n",
    "Example: In a pharmaceutical study comparing the effects of multiple drug treatments and a placebo, an ANOVA indicates significant differences. The Bonferroni-Dunn test can be applied to compare each drug treatment with the placebo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63063c",
   "metadata": {},
   "source": [
    "# 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31115733",
   "metadata": {},
   "source": [
    "To conduct a one-way ANOVA in Python, you can use the scipy.stats module. Here's an example code snippet to perform a one-way ANOVA on weight loss data for three diets (A, B, and C):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0547d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA Results:\n",
      "F-Statistic: 21.809565795751933\n",
      "p-value: 5.076768176045347e-09\n",
      "The one-way ANOVA indicates significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generate example weight loss data for three diets\n",
    "np.random.seed(42)  # For reproducibility\n",
    "data_A = np.random.normal(loc=2, scale=1, size=50)  # Mean weight loss for diet A\n",
    "data_B = np.random.normal(loc=3, scale=1, size=50)  # Mean weight loss for diet B\n",
    "data_C = np.random.normal(loc=2.5, scale=1, size=50)  # Mean weight loss for diet C\n",
    "\n",
    "# Combine the data into a single array\n",
    "all_data = np.concatenate([data_A, data_B, data_C])\n",
    "\n",
    "# Create corresponding group labels\n",
    "group_labels = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(data_A, data_B, data_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"One-way ANOVA Results:\")\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The one-way ANOVA indicates significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There is not enough evidence to conclude significant differences between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54539ff1",
   "metadata": {},
   "source": [
    "# 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b12f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         sum_sq    df         F    PR(>F)\n",
      "Program               15.717327   2.0  0.344485  0.709581\n",
      "Experience             2.994142   1.0  0.131248  0.718051\n",
      "Program:Experience     9.952457   2.0  0.218133  0.804472\n",
      "Residual            1916.273490  84.0       NaN       NaN\n",
      "\n",
      "Interpretation:\n",
      "There is no significant main effect of Program.\n",
      "There is no significant main effect of Experience.\n",
      "There is no significant interaction effect between Program and Experience.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a DataFrame with random data\n",
    "data = pd.DataFrame({\n",
    "    'Time': np.random.normal(loc=20, scale=5, size=90),  # Overall mean time\n",
    "    'Program': np.repeat(['A', 'B', 'C'], 30),\n",
    "    'Experience': np.tile(['Novice', 'Experienced'], 45),\n",
    "})\n",
    "\n",
    "# Convert categorical variables to categorical data type\n",
    "data['Program'] = data['Program'].astype('category')\n",
    "data['Experience'] = data['Experience'].astype('category')\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "formula = 'Time ~ Program + Experience + Program:Experience'\n",
    "model = ols(formula, data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Interpretation of main effects and interaction effects\n",
    "alpha = 0.05\n",
    "print(\"\\nInterpretation:\")\n",
    "if anova_table['PR(>F)']['Program'] < alpha:\n",
    "    print(\"There is a significant main effect of Program.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Program.\")\n",
    "\n",
    "if anova_table['PR(>F)']['Experience'] < alpha:\n",
    "    print(\"There is a significant main effect of Experience.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Experience.\")\n",
    "\n",
    "if anova_table['PR(>F)']['Program:Experience'] < alpha:\n",
    "    print(\"There is a significant interaction effect between Program and Experience.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between Program and Experience.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586b8a4",
   "metadata": {},
   "source": [
    "# 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db65d054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test Results:\n",
      "t-statistic: -4.108723928204809\n",
      "p-value: 8.261945608702611e-05\n",
      "The two-sample t-test indicates a significant difference in test scores between the control and experimental groups.\n",
      "\n",
      "One-way ANOVA Results for Post-hoc Test:\n",
      "F-statistic: 16.88161231820275\n",
      "p-value: 8.261945608702588e-05\n",
      "\n",
      "Post-hoc Tukey HSD Test Results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "Control Experimental   7.4325 0.0001 3.8427 11.0224   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate example data for control group (traditional teaching) and experimental group (new teaching)\n",
    "control_group = np.random.normal(loc=70, scale=10, size=50)\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=50)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the results of the t-test\n",
    "print(\"Two-sample t-test Results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check for significance\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The two-sample t-test indicates a significant difference in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the control and experimental groups.\")\n",
    "\n",
    "# Post-hoc test (Bonferroni correction)\n",
    "if p_value < alpha:\n",
    "    # Combine data for post-hoc test\n",
    "    all_data = np.concatenate([control_group, experimental_group])\n",
    "    \n",
    "    # Create corresponding group labels\n",
    "    group_labels = ['Control'] * 50 + ['Experimental'] * 50\n",
    "    \n",
    "    # Perform one-way ANOVA for post-hoc test\n",
    "    f_statistic, anova_p_value = f_oneway(control_group, experimental_group)\n",
    "    \n",
    "    # Print the results of the one-way ANOVA\n",
    "    print(\"\\nOne-way ANOVA Results for Post-hoc Test:\")\n",
    "    print(\"F-statistic:\", f_statistic)\n",
    "    print(\"p-value:\", anova_p_value)\n",
    "    \n",
    "    # Perform post-hoc Tukey HSD test\n",
    "    tukey_results = pairwise_tukeyhsd(all_data, group_labels)\n",
    "    \n",
    "    # Print the results of the post-hoc Tukey HSD test\n",
    "    print(\"\\nPost-hoc Tukey HSD Test Results:\")\n",
    "    print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d59b5",
   "metadata": {},
   "source": [
    "# 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0dfd914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA Results:\n",
      "F-statistic: 29.199185903529578\n",
      "p-value: 1.9849398798210062e-10\n",
      "The one-way ANOVA indicates a significant difference in daily sales between the three stores.\n",
      "\n",
      "Post-hoc Tukey HSD Test Results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1  group2 meandiff p-adj   lower    upper   reject\n",
      "--------------------------------------------------------\n",
      "Store A Store B 102.1376    0.0  70.1016 134.1736   True\n",
      "Store A Store C   60.116 0.0001    28.08   92.152   True\n",
      "Store B Store C -42.0216 0.0067 -74.0576  -9.9856   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate example data for daily sales of three stores\n",
    "store_A_sales = np.random.normal(loc=1000, scale=50, size=30)\n",
    "store_B_sales = np.random.normal(loc=1100, scale=60, size=30)\n",
    "store_C_sales = np.random.normal(loc=1050, scale=55, size=30)\n",
    "\n",
    "# Combine data for one-way ANOVA\n",
    "all_sales = np.concatenate([store_A_sales, store_B_sales, store_C_sales])\n",
    "\n",
    "# Create corresponding group labels\n",
    "group_labels = ['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(store_A_sales, store_B_sales, store_C_sales)\n",
    "\n",
    "# Print the results of the one-way ANOVA\n",
    "print(\"One-way ANOVA Results:\")\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check for significance\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The one-way ANOVA indicates a significant difference in daily sales between the three stores.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in daily sales between the three stores.\")\n",
    "\n",
    "# Post-hoc test (Tukey HSD)\n",
    "if p_value < alpha:\n",
    "    # Perform post-hoc Tukey HSD test\n",
    "    tukey_results = pairwise_tukeyhsd(all_sales, group_labels)\n",
    "    \n",
    "    # Print the results of the post-hoc Tukey HSD test\n",
    "    print(\"\\nPost-hoc Tukey HSD Test Results:\")\n",
    "    print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf3989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
